# Multilingual Customer Support SFT with QLoRA

Проект по **instruction fine-tuning** большой языковой модели для задачи генерации ответов службы поддержки на мультиязычных тикетах. 
Модель обучается отвечать на письмо пользователя (Subject + Body) в том же языке, в стиле вежливого и практичного саппорта.

Датасет: **Customer IT Support - Ticket Dataset** (Kaggle) - https://www.kaggle.com/datasets/tobiasbueck/multilingual-customer-support-tickets
В проекте используется **QLoRA**: базовая модель загружается в 4-bit (bitsandbytes), а обучаются только LoRA-адаптеры (PEFT).

## Действия модели

- Принимает текст тикета пользователя (subject + body)
- Генерирует корректный, вежливый ответ поддержки
- Старается сохранять язык тикета
- При нехватке данных — задаёт уточняющие вопросы

## Стек технологий

- **Python**, **Jupyter Notebook**
- **PyTorch**
- **Hugging Face Transformers**
- **TRL** (SFTTrainer)
- **PEFT** (LoRA / QLoRA)
- **bitsandbytes** (4-bit quantization, NF4)
- **Hugging Face Datasets**
- **Evaluate** (ROUGE, BERTScore)
- **CUDA**

## Структура проекта

Весь код реализован в одном ноутбуке, но логически разделён на этапы.

### Этап 1 — Формирование обучающих примеров
Данные конвертируются в prompt-completion формат для SFT:

- `prompt`:
  - `system`: инструкции для модели
  - `user`: тикет пользователя (subject + body)
- `completion`:
  - `assistant`: целевой ответ из `answer`

Это позволяет обучать модель в стиле “чат-инструкций”: модель учится не просто продолжать текст, а следовать роли и задаче.

### Этап 2 — Разбиение на train/val/test
- Данные разбиваются на train / validation / test
- Используется фиксированный seed для воспроизводимости

### Этап 3 — Загрузка модели в 4-bit (QLoRA)
- Базовая LLM (Qwen2.5-1.5B-Instruct) загружается с `BitsAndBytesConfig(load_in_4bit=True)`
- Используется квантование NF4 + double quantization

Зачем это нужно:
- 4-bit позволяет держать модель в памяти даже на небольших GPU
- обучаются только маленькие LoRA-слои, что быстрее и дешевле

### Этап 4 — Настройка LoRA-адаптеров (PEFT)
- Конфиг LoRA
- Target modules: выбор изменяемых слоев модели
- Обучаются только LoRA веса, базовая модель заморожена

### Этап 5 — Обучение (SFTTrainer)
- Используется trl.SFTTrainer + SFTConfig
- Включены:
  - `gradient_accumulation`
  - `gradient_checkpointing`
  - периодическая оценка на validation
  - сохранение чекпоинтов и LoRA адаптеров

Результат обучения:
- сохраняются LoRA-адаптеры и токенизатор

### Этап 6 — Evaluation: Perplexity + ROUGE + BERTScore
Оценка качества проводится в двух направлениях:

#### 1) Вероятностная метрика (качество предсказания токенов)
- **Validation perplexity** рассчитывается через eval_loss: ppl = exp(eval_loss)

#### 2) Текстовые метрики генерации (на test выборке)
- Генерация ответов на тестовых тикетах
- Сравнение с эталонными ответами через:
  - ROUGE-1 / ROUGE-2 / ROUGE-L / ROUGE-Lsum
  - BERTScore (F1 avg) для multilingual семантического совпадения

## Результаты

### Validation
- **Validation perplexity:** 2.9322 - хороший результат. Модель уверенно воспроизводит распределение токенов ответов на валидации (низкий `eval_loss`) и действительно выучила стиль/структуру саппорт-ответов.

### Текстовые метрики
- **ROUGE:**  
  - rouge1: 0.3837
  - rouge2: 0.1553
  - rougeL: 0.2652
  - rougeLsum: 0.2647
Для задач поддержки существует много корректных формулировок, поэтому ROUGE часто недооценивает качество (перефразирование, иной порядок шагов).
- **BERTScore (F1 avg):** 0.7551. BERTScore лучше отражает смысловую близость к эталонному ответу, даже если текст отличается лексически; значение ~0.75 показывает, что модельные ответы в среднем семантически близки к эталонным.