{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13959267,"sourceType":"datasetVersion","datasetId":5268504}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:41:43.239621Z","iopub.execute_input":"2026-01-19T05:41:43.240078Z","iopub.status.idle":"2026-01-19T05:41:44.758366Z","shell.execute_reply.started":"2026-01-19T05:41:43.240038Z","shell.execute_reply":"2026-01-19T05:41:44.757625Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/multilingual-customer-support-tickets/dataset-tickets-multi-lang-4-20k.csv\n/kaggle/input/multilingual-customer-support-tickets/dataset-tickets-german_normalized_50_5_2.csv\n/kaggle/input/multilingual-customer-support-tickets/dataset-tickets-multi-lang3-4k.csv\n/kaggle/input/multilingual-customer-support-tickets/dataset-tickets-german_normalized.csv\n/kaggle/input/multilingual-customer-support-tickets/aa_dataset-tickets-multi-lang-5-2-50-version.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip -q install accelerate trl bitsandbytes rouge_score bert_score peft evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:41:44.759807Z","iopub.execute_input":"2026-01-19T05:41:44.760136Z","iopub.status.idle":"2026-01-19T05:41:52.362175Z","shell.execute_reply.started":"2026-01-19T05:41:44.760114Z","shell.execute_reply":"2026-01-19T05:41:52.361265Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/532.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\n\nimport torch\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import LoraConfig\nfrom trl import SFTConfig, SFTTrainer\nimport evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:41:52.363525Z","iopub.execute_input":"2026-01-19T05:41:52.364174Z","iopub.status.idle":"2026-01-19T05:42:27.124666Z","shell.execute_reply.started":"2026-01-19T05:41:52.364141Z","shell.execute_reply":"2026-01-19T05:42:27.123874Z"}},"outputs":[{"name":"stderr","text":"2026-01-19 05:42:08.353477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768801328.554174      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768801328.609865      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768801329.230835      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768801329.230876      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768801329.230879      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768801329.230882      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"SEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)\nif device == \"cuda\":\n    print(\"GPU:\", torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:27.126644Z","iopub.execute_input":"2026-01-19T05:42:27.126909Z","iopub.status.idle":"2026-01-19T05:42:27.136343Z","shell.execute_reply.started":"2026-01-19T05:42:27.126884Z","shell.execute_reply":"2026-01-19T05:42:27.135770Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/multilingual-customer-support-tickets/aa_dataset-tickets-multi-lang-5-2-50-version.csv\"\nMODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\nOUTPUT_DIR = \"/kaggle/working/qlora_ticket_support_model\"\n\nMAX_LENGTH = 1024\nTRAIN_RATIO = 0.96\nVAL_RATIO = 0.02\nTEST_RATIO = 0.02\n\nGEN_MAX_NEW_TOKENS = 180\nGEN_TEMPERATURE = 0.0\nGEN_DO_SAMPLE = False\n\nEVAL_SAMPLE_SIZE = 300","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:27.137108Z","iopub.execute_input":"2026-01-19T05:42:27.137363Z","iopub.status.idle":"2026-01-19T05:42:27.153435Z","shell.execute_reply.started":"2026-01-19T05:42:27.137341Z","shell.execute_reply":"2026-01-19T05:42:27.152778Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(DATA_PATH)\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:27.154374Z","iopub.execute_input":"2026-01-19T05:42:27.154678Z","iopub.status.idle":"2026-01-19T05:42:28.153503Z","shell.execute_reply.started":"2026-01-19T05:42:27.154643Z","shell.execute_reply":"2026-01-19T05:42:28.152922Z"}},"outputs":[{"name":"stdout","text":"Shape: (28587, 16)\nColumns: ['subject', 'body', 'answer', 'type', 'queue', 'priority', 'language', 'version', 'tag_1', 'tag_2', 'tag_3', 'tag_4', 'tag_5', 'tag_6', 'tag_7', 'tag_8']\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             subject  \\\n0                    Wesentlicher Sicherheitsvorfall   \n1                                 Account Disruption   \n2  Query About Smart Home System Integration Feat...   \n\n                                                body  \\\n0  Sehr geehrtes Support-Team,\\n\\nich möchte eine...   \n1  Dear Customer Support Team,\\n\\nI am writing to...   \n2  Dear Customer Support Team,\\n\\nI hope this mes...   \n\n                                              answer      type  \\\n0  Vielen Dank für die Meldung des kritischen Sic...  Incident   \n1  Thank you for reaching out, <name>. We are awa...  Incident   \n2  Thank you for your inquiry. Our products suppo...   Request   \n\n                   queue priority language  version     tag_1       tag_2  \\\n0      Technical Support     high       de       51  Security      Outage   \n1      Technical Support     high       en       51   Account  Disruption   \n2  Returns and Exchanges   medium       en       51   Product     Feature   \n\n          tag_3        tag_4         tag_5 tag_6 tag_7 tag_8  \n0    Disruption  Data Breach           NaN   NaN   NaN   NaN  \n1        Outage           IT  Tech Support   NaN   NaN   NaN  \n2  Tech Support          NaN           NaN   NaN   NaN   NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>body</th>\n      <th>answer</th>\n      <th>type</th>\n      <th>queue</th>\n      <th>priority</th>\n      <th>language</th>\n      <th>version</th>\n      <th>tag_1</th>\n      <th>tag_2</th>\n      <th>tag_3</th>\n      <th>tag_4</th>\n      <th>tag_5</th>\n      <th>tag_6</th>\n      <th>tag_7</th>\n      <th>tag_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wesentlicher Sicherheitsvorfall</td>\n      <td>Sehr geehrtes Support-Team,\\n\\nich möchte eine...</td>\n      <td>Vielen Dank für die Meldung des kritischen Sic...</td>\n      <td>Incident</td>\n      <td>Technical Support</td>\n      <td>high</td>\n      <td>de</td>\n      <td>51</td>\n      <td>Security</td>\n      <td>Outage</td>\n      <td>Disruption</td>\n      <td>Data Breach</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Account Disruption</td>\n      <td>Dear Customer Support Team,\\n\\nI am writing to...</td>\n      <td>Thank you for reaching out, &lt;name&gt;. We are awa...</td>\n      <td>Incident</td>\n      <td>Technical Support</td>\n      <td>high</td>\n      <td>en</td>\n      <td>51</td>\n      <td>Account</td>\n      <td>Disruption</td>\n      <td>Outage</td>\n      <td>IT</td>\n      <td>Tech Support</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Query About Smart Home System Integration Feat...</td>\n      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n      <td>Thank you for your inquiry. Our products suppo...</td>\n      <td>Request</td>\n      <td>Returns and Exchanges</td>\n      <td>medium</td>\n      <td>en</td>\n      <td>51</td>\n      <td>Product</td>\n      <td>Feature</td>\n      <td>Tech Support</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"SYSTEM_PROMPT = (\n    \"You are a helpful, professional customer support agent. \"\n    \"Write a clear, polite and actionable reply. \"\n    \"If information is missing, ask concise follow-up questions. \"\n    \"Keep the same language as the user's ticket.\")\n\ndef make_example(row):\n    subject = str(row[\"subject\"]) if pd.notna(row[\"subject\"]) else \"\"\n    body = str(row[\"body\"]) if pd.notna(row[\"body\"]) else \"\"\n    answer = str(row[\"answer\"]) if pd.notna(row[\"answer\"]) else \"\"\n\n    user_msg = (\n        \"Please draft a customer support reply.\\n\\n\"\n        f\"Subject: {subject}\\n\\n\"\n        f\"Body:\\n{body}\\n\")\n\n    prompt = [\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": user_msg},]\n    completion = [\n        {\"role\": \"assistant\", \"content\": answer}]\n    return {\n        \"prompt\": prompt,\n        \"completion\": completion,\n        \"language\": row.get(\"language\", None),\n        \"priority\": row.get(\"priority\", None),\n        \"queue\": row.get(\"queue\", None),\n        \"type\": row.get(\"type\", None)}\n\nexamples = [make_example(r) for _, r in df.iterrows()]\nds = Dataset.from_list(examples)\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:28.154364Z","iopub.execute_input":"2026-01-19T05:42:28.154683Z","iopub.status.idle":"2026-01-19T05:42:30.150779Z","shell.execute_reply.started":"2026-01-19T05:42:28.154652Z","shell.execute_reply":"2026-01-19T05:42:30.150138Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'completion', 'language', 'priority', 'queue', 'type'],\n    num_rows: 28587\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tmp = ds.train_test_split(test_size=(1.0 - TRAIN_RATIO), seed=SEED, shuffle=True)\ntrain_ds = tmp[\"train\"]\ntemp_ds = tmp[\"test\"]\nval_size = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\ntmp2 = temp_ds.train_test_split(test_size=(1.0 - val_size), seed=SEED, shuffle=True)\nval_ds = tmp2[\"train\"]\ntest_ds = tmp2[\"test\"]\n\nprint(\"Train:\", len(train_ds))\nprint(\"Val:  \", len(val_ds))\nprint(\"Test: \", len(test_ds))\n\ntrain_ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:30.151733Z","iopub.execute_input":"2026-01-19T05:42:30.152041Z","iopub.status.idle":"2026-01-19T05:42:30.195190Z","shell.execute_reply.started":"2026-01-19T05:42:30.152008Z","shell.execute_reply":"2026-01-19T05:42:30.194583Z"}},"outputs":[{"name":"stdout","text":"Train: 27443\nVal:   572\nTest:  572\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'prompt': [{'content': \"You are a helpful, professional customer support agent. Write a clear, polite and actionable reply. If information is missing, ask concise follow-up questions. Keep the same language as the user's ticket.\",\n   'role': 'system'},\n  {'content': 'Please draft a customer support reply.\\n\\nSubject: \\n\\nBody:\\nHello Customer Support, I am inquiring about optimizing investment strategies using data analytics products and services. Could you provide some insights on how to leverage these tools to make informed decisions? I would greatly appreciate any guidance on best practices for implementing data analytics in investment strategies. Additionally, could you let me know what products and services are available to assist in this process? Thank you for your time and assistance. I look forward to hearing back soon.\\n',\n   'role': 'user'}],\n 'completion': [{'content': 'Dear [Name], we appreciate your inquiry regarding optimizing investment strategies using data analytics products and services. Our team can provide guidance and best practices to help you leverage the available tools for making informed decisions. Please contact [Tel Number] to discuss and explore suitable options that meet your needs. Thank you.',\n   'role': 'assistant'}],\n 'language': 'en',\n 'priority': 'high',\n 'queue': 'Billing and Payments',\n 'type': 'Request'}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True)\nmodel.config.use_cache = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:30.196003Z","iopub.execute_input":"2026-01-19T05:42:30.196209Z","iopub.status.idle":"2026-01-19T05:42:57.263209Z","shell.execute_reply.started":"2026-01-19T05:42:30.196189Z","shell.execute_reply":"2026-01-19T05:42:57.262562Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d411d48936403582e6a08479b2936c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1c93055eeeb4b2c831134a3ec6d30d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1239631b2806409fa22fae8eb44e7449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"400311b3b2df48d982ae32eeac0c544b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1c2350d227410aba35eb4b335600f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b041ab6f35f44cb28374e3ec7c10a46a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c7515c293994e7a9538667b403bb066"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"])\n\ntraining_args = SFTConfig(\n    output_dir=OUTPUT_DIR,\n    max_length=MAX_LENGTH,\n    packing=True,\n    num_train_epochs=1,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,\n    learning_rate=1e-4,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"cosine\",\n    logging_steps=25,\n    eval_strategy=\"steps\",\n    eval_steps=200,\n    save_steps=200,\n    save_total_limit=2,\n    bf16=True,\n    gradient_checkpointing=True,\n    report_to=\"none\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:57.265485Z","iopub.execute_input":"2026-01-19T05:42:57.266314Z","iopub.status.idle":"2026-01-19T05:42:57.294419Z","shell.execute_reply.started":"2026-01-19T05:42:57.266288Z","shell.execute_reply":"2026-01-19T05:42:57.293641Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    processing_class=tokenizer,\n    peft_config=peft_config)\n\ntrainer.train()\n\ntrainer.save_model(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T05:42:57.295327Z","iopub.execute_input":"2026-01-19T05:42:57.295580Z","iopub.status.idle":"2026-01-19T10:14:50.671281Z","shell.execute_reply.started":"2026-01-19T05:42:57.295547Z","shell.execute_reply":"2026-01-19T10:14:50.670417Z"}},"outputs":[{"name":"stderr","text":"WARNING:trl.trainer.sft_trainer:Padding-free training is enabled, but the attention implementation is not set to a supported flash attention variant. Padding-free training flattens batches into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn2, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation` in the model configuration to one of these supported options or verify that your attention mechanism can handle flattened sequences.\nWARNING:trl.trainer.sft_trainer:You are using packing, but the attention implementation is not set to a supported flash attention variant. Packing gathers multiple samples into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn2, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to cross-contamination between samples. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation` in the model configuration to one of these supported options.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/27443 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b38a665a93594b79979a651083d2d83f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing train dataset:   0%|          | 0/27443 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0316455380b4f25b1900f954a6dc1b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/572 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e7f35368734327bcd3e29fbcc754af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing eval dataset:   0%|          | 0/572 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"035c79504ca74b2ba99d7c11c1265c30"}},"metadata":{}},{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='396' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [396/396 4:30:20, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>1.074400</td>\n      <td>1.100415</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/qlora_ticket_support_model/tokenizer_config.json',\n '/kaggle/working/qlora_ticket_support_model/special_tokens_map.json',\n '/kaggle/working/qlora_ticket_support_model/chat_template.jinja',\n '/kaggle/working/qlora_ticket_support_model/vocab.json',\n '/kaggle/working/qlora_ticket_support_model/merges.txt',\n '/kaggle/working/qlora_ticket_support_model/added_tokens.json',\n '/kaggle/working/qlora_ticket_support_model/tokenizer.json')"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"eval_out = trainer.evaluate()\nprint(eval_out)\n\nif \"eval_loss\" in eval_out:\n    ppl = math.exp(eval_out[\"eval_loss\"]) if eval_out[\"eval_loss\"] < 20 else float(\"inf\")\n    print(\"Validation perplexity:\", ppl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:14:50.672612Z","iopub.execute_input":"2026-01-19T10:14:50.673230Z","iopub.status.idle":"2026-01-19T10:16:44.591217Z","shell.execute_reply.started":"2026-01-19T10:14:50.673186Z","shell.execute_reply":"2026-01-19T10:16:44.590620Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [68/68 01:52]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 1.075737476348877, 'eval_runtime': 113.9078, 'eval_samples_per_second': 1.194, 'eval_steps_per_second': 0.597}\nValidation perplexity: 2.9321544979657443\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")\nbertscore = evaluate.load(\"bertscore\")\n\nn_test = len(test_ds)\nn_eval = min(EVAL_SAMPLE_SIZE, n_test)\ntest_subset = test_ds.select(range(n_eval))\n\nprint(\"Evaluating on:\", n_eval, \"samples\")\n\ndef generate_answer_from_prompt(prompt_messages):\n    input_ids = tokenizer.apply_chat_template(\n        prompt_messages,\n        tokenize=True,\n        add_generation_prompt=True,\n        return_tensors=\"pt\")\n\n    input_ids = input_ids.to(model.device)\n    with torch.no_grad():\n        gen_ids = model.generate(\n            input_ids=input_ids,\n            max_new_tokens=GEN_MAX_NEW_TOKENS,\n            do_sample=GEN_DO_SAMPLE,\n            temperature=GEN_TEMPERATURE,\n            top_p=1.0,\n            pad_token_id=tokenizer.pad_token_id,\n            eos_token_id=tokenizer.eos_token_id)\n    gen_new = gen_ids[0][input_ids.shape[-1]:]\n    text = tokenizer.decode(gen_new, skip_special_tokens=True).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:16:44.592065Z","iopub.execute_input":"2026-01-19T10:16:44.592325Z","iopub.status.idle":"2026-01-19T10:16:48.204572Z","shell.execute_reply.started":"2026-01-19T10:16:44.592302Z","shell.execute_reply":"2026-01-19T10:16:48.203999Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f944a63502f04a36b05d76255f169a62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7536c6620f94478b94d1a16dabfb955"}},"metadata":{}},{"name":"stdout","text":"Evaluating on: 300 samples\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"preds = []\nrefs = []\nfor i in range(n_eval):\n    ex = test_subset[i]\n    prompt = ex[\"prompt\"]\n    ref = ex[\"completion\"][0][\"content\"]\n    pred = generate_answer_from_prompt(prompt)\n    preds.append(pred)\n    refs.append(ref)\n    if (i + 1) % 25 == 0:\n        print(\"Done\", i + 1, \"/\", n_eval)\nprint(\"Sample prediction:\\n\", preds[0])\nprint(\"\\nReference:\\n\", refs[0])\n\nrouge_scores = rouge.compute(predictions=preds, references=refs)\nbert_scores = bertscore.compute(\n    predictions=preds,\n    references=refs,\n    model_type=\"bert-base-multilingual-cased\",\n    rescale_with_baseline=False)\n\nprint(\"ROUGE:\", {k: round(v, 4) for k, v in rouge_scores.items()})\nprint(\"BERTScore (F1 avg):\", round(float(np.mean(bert_scores[\"f1\"])), 4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T10:16:48.205400Z","iopub.execute_input":"2026-01-19T10:16:48.206014Z","iopub.status.idle":"2026-01-19T11:01:08.341474Z","shell.execute_reply.started":"2026-01-19T10:16:48.205988Z","shell.execute_reply":"2026-01-19T11:01:08.340733Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"Done 25 / 300\nDone 50 / 300\nDone 75 / 300\nDone 100 / 300\nDone 125 / 300\nDone 150 / 300\nDone 175 / 300\nDone 200 / 300\nDone 225 / 300\nDone 250 / 300\nDone 275 / 300\nDone 300 / 300\nSample prediction:\n Sehr geehrte [Name], vielen Dank für Ihre Nachricht bezüglich des Verbindungsproblems mit Ihrem Google Nest Wifi Router. Ich verstehe, dass dies die Nutzung von Online-Bereitstellungen und der Kommunikation mit Ihren Kunden beeinträchtigt hat. Um Ihnen besser zu helfen, bitte ich Sie, mehr Details über die neuesten Firmware-Updates und die Netzwerkkonfiguration zu geben. Falls notwendig, können wir einen Anruf vereinbaren, um das Problem genauer zu besprechen. Bitte teilen Sie mir eine passende Zeit mit, damit wir Kontakt aufnehmen können.\n\nReference:\n Wir sind Ihnen bei den Verbindungsproblemen mit Ihrem Google Nest Wifi Router behilflich. Für ein präzises Troubleshooting könnten Sie bitte den Modellnamen und die Firmware-Version des Routers nennen. Eine gute Zeit für einen Anruf ist <tel_num>. Wir werden diese Informationen weiter an den Techniker mitteilen, der eine Diagnose durchführen kann.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a82bb761a59f4e94891d9230413139e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c109bd4a563441758889f0e86b36a596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b645750d048a4654b29d2a10648634e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dca16091dc84d17afc7873c6241ee3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2ff290cc48c4e28ac875f56ca007142"}},"metadata":{}},{"name":"stdout","text":"ROUGE: {'rouge1': np.float64(0.3837), 'rouge2': np.float64(0.1553), 'rougeL': np.float64(0.2652), 'rougeLsum': np.float64(0.2647)}\nBERTScore (F1 avg): 0.7551\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"demo_subject = \"Refund request for duplicate charge\"\n\ndemo_body = (\n    \"Hi, I was charged twice for order #A18473 on January 12. \"\n    \"I only placed one order and the second payment is pending in my bank. \"\n    \"Can you confirm if this is a duplicate charge and refund it? \"\n    \"Attached: screenshot of the two transactions.\")\n\ndemo_prompt = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\"role\": \"user\", \"content\": \"Please draft a customer support reply.\\n\\nSubject: \"\n     + demo_subject + \"\\n\\nBody:\\n\" + demo_body + \"\\n\"}]\n\ndemo_answer = generate_answer_from_prompt(demo_prompt)\nprint(demo_answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T11:03:47.180814Z","iopub.execute_input":"2026-01-19T11:03:47.181107Z","iopub.status.idle":"2026-01-19T11:03:50.634958Z","shell.execute_reply.started":"2026-01-19T11:03:47.181081Z","shell.execute_reply":"2026-01-19T11:03:50.634341Z"}},"outputs":[{"name":"stdout","text":"We will investigate the duplicate charge issue with order A18473. Please provide your account number so we can proceed with the refund process.\n","output_type":"stream"}],"execution_count":17}]}